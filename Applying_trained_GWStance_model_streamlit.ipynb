{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPHLOtffOKXV4yqcgB7U5D+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aaalexlit/omdena_climate_change_challenge_notebooks/blob/main/Applying_trained_GWStance_model_streamlit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "6zThdeoh8UoQ"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "## we need this to be able to download big-ish files from GDrive\n",
        "!pip3 install --upgrade gdown\n",
        "!pip install nltk transformers streamlit\n",
        "# Download the model\n",
        "!gdown https://drive.google.com/uc?id=12rVg_bpuDfZbdWRtEN2Jf6SNyMEnax76\n",
        "# Clone GWStance repo \n",
        "!git clone https://github.com/yiweiluo/GWStance.git\n",
        "# Untar the model\n",
        "!tar -xvzf final_model.tar.gz\n",
        "# Install virtualenv and all the requirements\n",
        "!pip install virtualenv\n",
        "!virtualenv gwstance\n",
        "!source /content/gwstance/bin/activate; pip install transformers scipy pandas matplotlib scikit-learn tqdm tensorboard boto3 torch torchvision\n",
        "# copy things for transformers\n",
        "!cp -r /content/GWStance/3_stance_detection/2_Stance_model/for_transformers/* /content/gwstance/lib/python3.9/site-packages/transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile GWStance_prediction.py\n",
        "import streamlit as st\n",
        "from transformers import AutoTokenizer, pipeline, RobertaForSequenceClassification\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize\n",
        "import torch\n",
        "import pandas as pd\n",
        "import subprocess\n",
        "\n",
        "label_mapping = {0: 'disagree', 1: 'neutral', 2: 'agree'}\n",
        "\n",
        "def is_about_climate(texts, model, tokenizer):\n",
        "    if torch.cuda.is_available():\n",
        "      device = 0\n",
        "      batch_size = 128\n",
        "    else:\n",
        "      device = -1\n",
        "      batch_size = 1\n",
        "    pipe = pipeline(\"text-classification\", model=model,\n",
        "                    tokenizer=tokenizer, device=device,\n",
        "                    truncation=True, padding=True)\n",
        "    labels = []\n",
        "    probs = []\n",
        "    for out in pipe(texts, batch_size=batch_size):\n",
        "        labels.append(out['label'])\n",
        "        probs.append(out['score'])\n",
        "    torch.cuda.empty_cache()\n",
        "    return labels, probs\n",
        "\n",
        "\n",
        "def filter_climate_related(sentences, model, tokenizer):\n",
        "    labels, _ = is_about_climate(sentences, model, tokenizer)\n",
        "    return [doc for label, doc in zip(labels, sentences) if label == 'Yes']\n",
        "\n",
        "def predict_climate_relatedness(sentences, model, tokenizer):\n",
        "  labels, probs = is_about_climate(sentences, model, tokenizer)\n",
        "  df_cli = pd.DataFrame(zip(sentences, labels, probs))\n",
        "  return df_cli\n",
        "    \n",
        "def predict_gw_stance(input_sentences, model, tokenizer):\n",
        "  sentences = filter_climate_related(input_sentences, model, tokenizer)\n",
        "\n",
        "  if not sentences:\n",
        "    print(\"No climate related sentences found in the text\")\n",
        "    return None\n",
        "  df = pd.DataFrame(sentences)\n",
        "  df[\"lab\"]= \"neutral\"\n",
        "  df[\"weight\"]= 1.0\n",
        "  df.to_csv('test.tsv', sep='\\t', index=False, header=False)\n",
        "\n",
        "  subprocess.run(\"python /content/GWStance/3_stance_detection/2_Stance_model/predict.py \\\n",
        "  /content/final_model/config.json \\\n",
        "  /content/final_model/no-dev \\\n",
        "  --data-dir /content/ \\\n",
        "  --transformers-dir /content/gwstance/lib/python3.9/site-packages/transformers\".split())\n",
        "\n",
        "  input_df = pd.read_csv(\"/content/test.tsv\", sep='\\t', header=None, names=[\"text\", \"fake1\", \"fake2\"])\n",
        "  preds_df = pd.read_csv(\"/content/final_model/no-dev/predictions_test.tsv\", sep='\\t')\n",
        "\n",
        "  res_df = input_df.join(preds_df)[[\"text\", \"predicted\"]]\n",
        "\n",
        "  res_df['predicted'] = res_df['predicted'].apply(lambda x: label_mapping[x])\n",
        "\n",
        "  return res_df\n",
        "\n",
        "@st.cache_resource\n",
        "def download_models():\n",
        "    nltk.download('punkt')\n",
        "\n",
        "    # Load the pre-trained model\n",
        "    model = RobertaForSequenceClassification.from_pretrained('kruthof/climateattention-10k-upscaled',num_labels=2)\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"climatebert/distilroberta-base-climate-f\")\n",
        "    return model, tokenizer\n",
        "\n",
        "# Create the Streamlit app\n",
        "def main():\n",
        "    st.set_page_config(page_title=\"Applying trained Global Warming stance model\", \n",
        "                       page_icon=\":earth_americas:\",\n",
        "                       layout='wide')\n",
        "    model, tokenizer = download_models()\n",
        "\n",
        "    # Add a sidebar with links\n",
        "    st.sidebar.title(\"Omdena, Local Chapter, ðŸ‡©ðŸ‡ª Cologne\")\n",
        "    project_link = '[Project Description](https://omdena.com/chapter-challenges/detecting-bias-in-climate-reporting-in-english-and-german-language-news-media/)'\n",
        "    st.sidebar.markdown(project_link, unsafe_allow_html=True)\n",
        "    github_link = '[Github Repo](https://github.com/OmdenaAI/cologne-germany-reporting-bias/)'\n",
        "    st.sidebar.markdown(github_link, unsafe_allow_html=True)\n",
        "\n",
        "    st.header(\"Applying trained Global Warming stance model to the sentences extracted from climate news articles\")\n",
        "    \n",
        "    tab_bias_detection, tab_how_to, tab_faq = st.tabs([\"Global Warming Stance Detection\", \"How-To\", \"FAQ\"])\n",
        "\n",
        "    with tab_bias_detection:\n",
        "      \n",
        "      st.write(\"\"\"Enter a Text below and click the Classify Button \n",
        "      to extract change related claim sentences from text and classify them\n",
        "      as agreeing with Global warming, disagreeing with Global Warming or neutral\"\"\")\n",
        "\n",
        "      text_input = st.text_area(\"Enter Text\")\n",
        "      input_sentences = sent_tokenize(text_input)\n",
        "\n",
        "      # Classify text and show result\n",
        "      if st.button(\"Detect Global Warming stance in climate related sentences\"):\n",
        "        with st.spinner(text='Performing stance detection'):\n",
        "          res = predict_gw_stance(input_sentences, model, tokenizer)\n",
        "          if res is not None:\n",
        "            st.dataframe(res, use_container_width=True)\n",
        "          else:\n",
        "            st.warning(\"None of the extracted sentences are climate related.\")\n",
        "\n",
        "      if st.button(\"Classify sentences from text\"):\n",
        "        with st.spinner(text='Classifying sentences as climate-related or not'):\n",
        "          res = predict_climate_relatedness(input_sentences, model, tokenizer)\n",
        "          st.dataframe(res, use_container_width=True)\n",
        "    \n",
        "    with tab_how_to:\n",
        "      st.write(\"tbd\")\n",
        "    \n",
        "    with tab_faq:\n",
        "      st.write(\"tbd\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-hzaiNE-Vowy",
        "outputId": "6abce5cf-b6e3-4e09-fb3f-309ced0dc24c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting GWStance_prediction.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run streamlit \n",
        "!streamlit run GWStance_prediction.py & npx localtunnel --port 8501"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GXF9F1QnXTo4",
        "outputId": "0502ccdb-711e-439c-fe96-ad5ca718d42d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[#######...........] / extract:localtunnel: verb lock using /root/.npm/_locks/s\u001b[0m\u001b[K\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to False.\n",
            "\u001b[0m\n",
            "\u001b[K\u001b[?25hnpx: installed 22 in 3.587s\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://35.196.118.197:8501\u001b[0m\n",
            "\u001b[0m\n",
            "your url is: https://odd-pumas-hang-35-196-118-197.loca.lt\n",
            "2023-03-17 21:42:52.291984: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-03-17 21:42:53.724661: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2023-03-17 21:42:53.724886: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2023-03-17 21:42:53.724915: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "Using transformers dir: /content/gwstance/lib/python3.9/site-packages/transformers\n",
            "['python', '/content/gwstance/lib/python3.9/site-packages/transformers/run_weighted.py', '--model_type', 'bert', '--task_name', 'climate-weight', '--do_eval', '--pred_file_name', 'predictions', '--do_lower_case', '--data_dir', '/content/', '--max_seq_length', '256', '--per_gpu_eval_batch_size=16', '--per_gpu_train_batch_size=16', '--output_dir', '/content/final_model/no-dev', '--overwrite_cache', '--overwrite_output_dir', '--model_name_or_path', '/content/final_model/no-dev', '--eval_partition', 'test', '--num_labels', '3']\n",
            "2023-03-17 21:45:43.962783: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2023-03-17 21:45:43.962975: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2023-03-17 21:45:43.963007: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "/usr/local/lib/python3.9/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
            "  warnings.warn(\"Can't initialize NVML\")\n",
            "03/17/2023 21:45:46 - WARNING - __main__ -   Process rank: -1, device: cpu, n_gpu: 0, distributed training: False, 16-bits training: False\n",
            "Num labels: 3\n",
            "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'LABEL_0', '1': 'LABEL_1'}. The number of labels wil be overwritten to 2.\n",
            "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'LABEL_0', '1': 'LABEL_1'}. The number of labels wil be overwritten to 2.\n",
            "03/17/2023 21:45:48 - INFO - __main__ -   Training/evaluation parameters Namespace(data_dir='/content/', model_type='bert', model_name_or_path='/content/final_model/no-dev', task_name='climate-weight', output_dir='/content/final_model/no-dev', config_name='', tokenizer_name='', cache_dir='', max_seq_length=256, do_train=False, do_eval=True, eval_partition='test', pred_file_name='predictions', evaluate_during_training=False, do_lower_case=True, do_text_b=False, per_gpu_train_batch_size=16, per_gpu_eval_batch_size=16, gradient_accumulation_steps=1, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=3.0, max_steps=-1, warmup_steps=0, logging_steps=500, save_steps=500, eval_all_checkpoints=False, no_cuda=False, overwrite_output_dir=True, overwrite_cache=True, seed=42, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', num_labels=3, n_gpu=0, device=device(type='cpu'), output_mode='classification')\n",
            "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'LABEL_0', '1': 'LABEL_1'}. The number of labels wil be overwritten to 2.\n",
            "03/17/2023 21:45:48 - INFO - __main__ -   Evaluate the following checkpoints: ['/content/final_model/no-dev']\n",
            "checkpoint: /content/final_model/no-dev\n",
            "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'LABEL_0', '1': 'LABEL_1'}. The number of labels wil be overwritten to 2.\n",
            "cached_features_file: /content/cached_test_no-dev_256_climate-weight\n",
            "True\n",
            "03/17/2023 21:45:50 - INFO - __main__ -   Creating features from dataset file at /content/\n",
            "num examples: 8\n",
            "args.eval_partition test\n",
            "examples: [InputExampleWeighted(guid='test-0', text_a='A Paris court has found France legally responsible for its failure to meet targets intended to reduce greenhouse gas emissions.', text_b=None, label='neutral'), InputExampleWeighted(guid='test-1', text_a='\"The lawsuit was launched by four NGOs, including Greenpeace France and Oxfam France, following an online petition that gathered 2.3 million signatures -- the largest in French history, according to organizers.Signatories hoped to \"\"compel the State to take all necessary measures to reduce greenhouse gas emissions\"\" to meet the 1.5 degrees Celsius (2.7 degrees Fahrenheit) target set by the Paris Agreement, according to the online petition.The Paris Agreement was signed by almost all the world\\'s countries, and seeks to limit global warming to well below 2 degrees Celsius (3.6 degrees Fahrenheit) and pursue efforts to limit it to 1.5 degrees Celsius (2.7 degrees Fahrenheit).France, which brokered the pact, has committed to reducing greenhouse gases by 40% by 2030, and has set itself a target of being carbon neutral by 2050.But NGOs accused the country\\'s authorities of insufficient policy actions needed to tackle climate change, and said that greenhouse gas emissions under the current government \"\"dropped at a pace that was twice as slow as the trajectories foreseen under the law.\"\"\"', text_b=None, label='neutral'), InputExampleWeighted(guid='test-2', text_a='\"This judgment also marks a victory for the truth: Until now, the state has denied that its climate policies were insufficient, despite mounting evidence,\"\" they said in a statement.\"', text_b=None, label='neutral')]\n",
            "03/17/2023 21:45:50 - INFO - classifier.glue_weighted -   Writing example 0/8\n",
            "03/17/2023 21:45:50 - INFO - classifier.glue_weighted -   *** Example ***\n",
            "03/17/2023 21:45:50 - INFO - classifier.glue_weighted -   guid: test-0\n",
            "03/17/2023 21:45:50 - INFO - classifier.glue_weighted -   input_ids: 101 1037 3000 2457 2038 2179 2605 10142 3625 2005 2049 4945 2000 3113 7889 3832 2000 5547 16635 3806 11768 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/17/2023 21:45:50 - INFO - classifier.glue_weighted -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/17/2023 21:45:50 - INFO - classifier.glue_weighted -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/17/2023 21:45:50 - INFO - classifier.glue_weighted -   label: neutral (id = 1)\n",
            "03/17/2023 21:45:50 - INFO - classifier.glue_weighted -   *** Example ***\n",
            "03/17/2023 21:45:50 - INFO - classifier.glue_weighted -   guid: test-1\n",
            "03/17/2023 21:45:50 - INFO - classifier.glue_weighted -   input_ids: 101 1000 1996 9870 2001 3390 2011 2176 22165 1010 2164 2665 5051 10732 2605 1998 23060 7011 2213 2605 1010 2206 2019 3784 9964 2008 5935 1016 1012 1017 2454 16442 1011 1011 1996 2922 1999 2413 2381 1010 2429 2000 18829 1012 3696 8844 3111 5113 2000 1000 1000 4012 11880 1996 2110 2000 2202 2035 4072 5761 2000 5547 16635 3806 11768 1000 1000 2000 3113 1996 1015 1012 1019 5445 8292 4877 4173 1006 1016 1012 1021 5445 6904 28362 25311 20175 1007 4539 2275 2011 1996 3000 3820 1010 2429 2000 1996 3784 9964 1012 1996 3000 3820 2001 2772 2011 2471 2035 1996 2088 1005 1055 3032 1010 1998 11014 2000 5787 3795 12959 2000 2092 2917 1016 5445 8292 4877 4173 1006 1017 1012 1020 5445 6904 28362 25311 20175 1007 1998 7323 4073 2000 5787 2009 2000 1015 1012 1019 5445 8292 4877 4173 1006 1016 1012 1021 5445 6904 28362 25311 20175 1007 1012 2605 1010 2029 20138 2098 1996 14790 1010 2038 5462 2000 8161 16635 15865 2011 2871 1003 2011 18540 2692 1010 1998 2038 2275 2993 1037 4539 1997 2108 6351 8699 2011 16327 2692 1012 2021 22165 5496 1996 2406 1005 1055 4614 1997 13990 3343 4506 2734 2000 11147 4785 2689 1010 1998 2056 2008 16635 3806 11768 2104 1996 2783 2231 1000 1000 3333 2012 1037 6393 2008 2001 3807 2004 4030 2004 1996 19817 13006 22471 18909 18921 19763 2078 2104 1996 2375 1012 1000 1000 1000 102 0 0\n",
            "03/17/2023 21:45:50 - INFO - classifier.glue_weighted -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0\n",
            "03/17/2023 21:45:50 - INFO - classifier.glue_weighted -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/17/2023 21:45:50 - INFO - classifier.glue_weighted -   label: neutral (id = 1)\n",
            "03/17/2023 21:45:50 - INFO - classifier.glue_weighted -   *** Example ***\n",
            "03/17/2023 21:45:50 - INFO - classifier.glue_weighted -   guid: test-2\n",
            "03/17/2023 21:45:50 - INFO - classifier.glue_weighted -   input_ids: 101 1000 2023 8689 2036 6017 1037 3377 2005 1996 3606 1024 2127 2085 1010 1996 2110 2038 6380 2008 2049 4785 6043 2020 13990 1010 2750 15986 3350 1010 1000 1000 2027 2056 1999 1037 4861 1012 1000 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/17/2023 21:45:50 - INFO - classifier.glue_weighted -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/17/2023 21:45:50 - INFO - classifier.glue_weighted -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/17/2023 21:45:50 - INFO - classifier.glue_weighted -   label: neutral (id = 1)\n",
            "03/17/2023 21:45:50 - INFO - classifier.glue_weighted -   *** Example ***\n",
            "03/17/2023 21:45:50 - INFO - classifier.glue_weighted -   guid: test-3\n",
            "03/17/2023 21:45:50 - INFO - classifier.glue_weighted -   input_ids: 101 1000 1000 1000 2023 2003 1996 2034 5038 2011 1996 5434 1997 1996 5368 1997 1996 2413 2110 2005 2049 4785 27118 7542 1010 1000 1000 12223 3170 13852 2239 1010 1037 5160 2005 2028 1997 1996 22165 1010 2056 2012 1037 2811 3034 2206 1996 6996 1012 1000 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/17/2023 21:45:50 - INFO - classifier.glue_weighted -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/17/2023 21:45:50 - INFO - classifier.glue_weighted -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/17/2023 21:45:50 - INFO - classifier.glue_weighted -   label: neutral (id = 1)\n",
            "03/17/2023 21:45:50 - INFO - classifier.glue_weighted -   *** Example ***\n",
            "03/17/2023 21:45:50 - INFO - classifier.glue_weighted -   guid: test-4\n",
            "03/17/2023 21:45:50 - INFO - classifier.glue_weighted -   input_ids: 101 1000 1000 1000 1996 6794 8920 3251 2045 2001 1037 28102 4957 2090 2023 12231 4053 1998 1996 2536 12510 2229 6884 2114 1996 2110 1999 1996 2954 2114 4785 2689 1012 1000 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/17/2023 21:45:50 - INFO - classifier.glue_weighted -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/17/2023 21:45:50 - INFO - classifier.glue_weighted -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/17/2023 21:45:50 - INFO - classifier.glue_weighted -   label: neutral (id = 1)\n",
            "03/17/2023 21:45:50 - INFO - __main__ -   Saving features into cached file /content/cached_test_no-dev_256_climate-weight\n",
            "03/17/2023 21:45:50 - INFO - __main__ -   ***** Running evaluation  *****\n",
            "03/17/2023 21:45:50 - INFO - __main__ -     Num examples = 8\n",
            "03/17/2023 21:45:50 - INFO - __main__ -     Batch size = 16\n",
            "Evaluating: 100% 1/1 [00:08<00:00,  8.12s/it]\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "03/17/2023 21:45:58 - INFO - __main__ -   ***** Eval results  *****\n",
            "03/17/2023 21:45:58 - INFO - __main__ -     acc = 0.875\n",
            "03/17/2023 21:45:58 - INFO - __main__ -     acc_and_f1 = {'acc': 0.875, 'micro_f1': 0.875, 'macro_f1': 0.4666666666666667, 'acc_and_macro_f1': 0.6708333333333334}\n",
            "03/17/2023 21:45:58 - INFO - __main__ -     cm = [[7 0]\n",
            " [1 0]]\n",
            "03/17/2023 21:45:58 - INFO - __main__ -     per_class = {'disagree': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0}, 'neutral': {'precision': 1.0, 'recall': 0.875, 'f1-score': 0.9333333333333333, 'support': 8}, 'agree': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0}, 'micro avg': {'precision': 0.875, 'recall': 0.875, 'f1-score': 0.875, 'support': 8}, 'macro avg': {'precision': 0.3333333333333333, 'recall': 0.2916666666666667, 'f1-score': 0.3111111111111111, 'support': 8}, 'weighted avg': {'precision': 1.0, 'recall': 0.875, 'f1-score': 0.9333333333333333, 'support': 8}}\n",
            "No climate related sentences found in the text\n",
            "Using transformers dir: /content/gwstance/lib/python3.9/site-packages/transformers\n",
            "['python', '/content/gwstance/lib/python3.9/site-packages/transformers/run_weighted.py', '--model_type', 'bert', '--task_name', 'climate-weight', '--do_eval', '--pred_file_name', 'predictions', '--do_lower_case', '--data_dir', '/content/', '--max_seq_length', '256', '--per_gpu_eval_batch_size=16', '--per_gpu_train_batch_size=16', '--output_dir', '/content/final_model/no-dev', '--overwrite_cache', '--overwrite_output_dir', '--model_name_or_path', '/content/final_model/no-dev', '--eval_partition', 'test', '--num_labels', '3']\n",
            "2023-03-17 21:50:05.761615: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2023-03-17 21:50:05.761932: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2023-03-17 21:50:05.761977: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "/usr/local/lib/python3.9/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
            "  warnings.warn(\"Can't initialize NVML\")\n",
            "03/17/2023 21:50:09 - WARNING - __main__ -   Process rank: -1, device: cpu, n_gpu: 0, distributed training: False, 16-bits training: False\n",
            "Num labels: 3\n",
            "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'LABEL_0', '1': 'LABEL_1'}. The number of labels wil be overwritten to 2.\n",
            "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'LABEL_0', '1': 'LABEL_1'}. The number of labels wil be overwritten to 2.\n",
            "03/17/2023 21:50:14 - INFO - __main__ -   Training/evaluation parameters Namespace(data_dir='/content/', model_type='bert', model_name_or_path='/content/final_model/no-dev', task_name='climate-weight', output_dir='/content/final_model/no-dev', config_name='', tokenizer_name='', cache_dir='', max_seq_length=256, do_train=False, do_eval=True, eval_partition='test', pred_file_name='predictions', evaluate_during_training=False, do_lower_case=True, do_text_b=False, per_gpu_train_batch_size=16, per_gpu_eval_batch_size=16, gradient_accumulation_steps=1, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=3.0, max_steps=-1, warmup_steps=0, logging_steps=500, save_steps=500, eval_all_checkpoints=False, no_cuda=False, overwrite_output_dir=True, overwrite_cache=True, seed=42, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', num_labels=3, n_gpu=0, device=device(type='cpu'), output_mode='classification')\n",
            "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'LABEL_0', '1': 'LABEL_1'}. The number of labels wil be overwritten to 2.\n",
            "03/17/2023 21:50:14 - INFO - __main__ -   Evaluate the following checkpoints: ['/content/final_model/no-dev']\n",
            "checkpoint: /content/final_model/no-dev\n",
            "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'LABEL_0', '1': 'LABEL_1'}. The number of labels wil be overwritten to 2.\n",
            "cached_features_file: /content/cached_test_no-dev_256_climate-weight\n",
            "True\n",
            "03/17/2023 21:50:17 - INFO - __main__ -   Creating features from dataset file at /content/\n",
            "num examples: 14\n",
            "args.eval_partition test\n",
            "examples: [InputExampleWeighted(guid='test-0', text_a='And of course, behind it all, the increasingly influential elephant in the room that is global climate change.', text_b=None, label='neutral'), InputExampleWeighted(guid='test-1', text_a='One expert suspects itâ€™s likely to have reset the national conversation about the climate crisis upon us.', text_b=None, label='neutral'), InputExampleWeighted(guid='test-2', text_a='â€œBut weâ€™re going to see more of these events, unless we can get on top of emissions and stop the climate from changing.â€ The scale of last nightâ€™s downpour has surprised even meteorologists whoâ€™d been tracking the system throughout the week.', text_b=None, label='neutral')]\n",
            "03/17/2023 21:50:17 - INFO - classifier.glue_weighted -   Writing example 0/14\n",
            "03/17/2023 21:50:17 - INFO - classifier.glue_weighted -   *** Example ***\n",
            "03/17/2023 21:50:17 - INFO - classifier.glue_weighted -   guid: test-0\n",
            "03/17/2023 21:50:17 - INFO - classifier.glue_weighted -   input_ids: 101 1998 1997 2607 1010 2369 2009 2035 1010 1996 6233 6383 10777 1999 1996 2282 2008 2003 3795 4785 2689 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/17/2023 21:50:17 - INFO - classifier.glue_weighted -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/17/2023 21:50:17 - INFO - classifier.glue_weighted -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/17/2023 21:50:17 - INFO - classifier.glue_weighted -   label: neutral (id = 1)\n",
            "03/17/2023 21:50:17 - INFO - classifier.glue_weighted -   *** Example ***\n",
            "03/17/2023 21:50:17 - INFO - classifier.glue_weighted -   guid: test-1\n",
            "03/17/2023 21:50:17 - INFO - classifier.glue_weighted -   input_ids: 101 2028 6739 13172 2009 1521 1055 3497 2000 2031 25141 1996 2120 4512 2055 1996 4785 5325 2588 2149 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/17/2023 21:50:17 - INFO - classifier.glue_weighted -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/17/2023 21:50:17 - INFO - classifier.glue_weighted -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/17/2023 21:50:17 - INFO - classifier.glue_weighted -   label: neutral (id = 1)\n",
            "03/17/2023 21:50:17 - INFO - classifier.glue_weighted -   *** Example ***\n",
            "03/17/2023 21:50:17 - INFO - classifier.glue_weighted -   guid: test-2\n",
            "03/17/2023 21:50:17 - INFO - classifier.glue_weighted -   input_ids: 101 1523 2021 2057 1521 2128 2183 2000 2156 2062 1997 2122 2824 1010 4983 2057 2064 2131 2006 2327 1997 11768 1998 2644 1996 4785 2013 5278 1012 1524 1996 4094 1997 2197 2305 1521 1055 2091 27757 2038 4527 2130 23879 16886 2040 1521 1040 2042 9651 1996 2291 2802 1996 2733 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/17/2023 21:50:17 - INFO - classifier.glue_weighted -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/17/2023 21:50:17 - INFO - classifier.glue_weighted -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/17/2023 21:50:17 - INFO - classifier.glue_weighted -   label: neutral (id = 1)\n",
            "03/17/2023 21:50:17 - INFO - classifier.glue_weighted -   *** Example ***\n",
            "03/17/2023 21:50:17 - INFO - classifier.glue_weighted -   guid: test-3\n",
            "03/17/2023 21:50:17 - INFO - classifier.glue_weighted -   input_ids: 101 1523 2017 1521 2310 2288 1037 11935 2659 2746 2046 1996 2047 3414 2555 1010 2073 17401 2031 2042 3728 2770 2004 2172 2004 1018 2278 2000 1020 2278 16676 2084 2779 1516 2025 2000 5254 2008 2009 1521 1055 2036 2042 2172 16676 2039 1999 1996 11034 2712 1010 1524 2053 3363 2056 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/17/2023 21:50:17 - INFO - classifier.glue_weighted -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/17/2023 21:50:17 - INFO - classifier.glue_weighted -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/17/2023 21:50:17 - INFO - classifier.glue_weighted -   label: neutral (id = 1)\n",
            "03/17/2023 21:50:17 - INFO - classifier.glue_weighted -   *** Example ***\n",
            "03/17/2023 21:50:17 - INFO - classifier.glue_weighted -   guid: test-4\n",
            "03/17/2023 21:50:17 - INFO - classifier.glue_weighted -   input_ids: 101 2008 1521 1055 2091 2000 2178 5016 3747 2099 2008 1521 1055 2085 4895 23773 6525 3468 1024 4785 2689 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/17/2023 21:50:17 - INFO - classifier.glue_weighted -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/17/2023 21:50:17 - INFO - classifier.glue_weighted -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/17/2023 21:50:17 - INFO - classifier.glue_weighted -   label: neutral (id = 1)\n",
            "03/17/2023 21:50:17 - INFO - __main__ -   Saving features into cached file /content/cached_test_no-dev_256_climate-weight\n",
            "03/17/2023 21:50:17 - INFO - __main__ -   ***** Running evaluation  *****\n",
            "03/17/2023 21:50:17 - INFO - __main__ -     Num examples = 14\n",
            "03/17/2023 21:50:17 - INFO - __main__ -     Batch size = 16\n",
            "Evaluating: 100% 1/1 [00:13<00:00, 13.55s/it]\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "03/17/2023 21:50:31 - INFO - __main__ -   ***** Eval results  *****\n",
            "03/17/2023 21:50:31 - INFO - __main__ -     acc = 0.5\n",
            "03/17/2023 21:50:31 - INFO - __main__ -     acc_and_f1 = {'acc': 0.5, 'micro_f1': 0.5, 'macro_f1': 0.3333333333333333, 'acc_and_macro_f1': 0.41666666666666663}\n",
            "03/17/2023 21:50:31 - INFO - __main__ -     cm = [[7 0]\n",
            " [7 0]]\n",
            "03/17/2023 21:50:31 - INFO - __main__ -     per_class = {'disagree': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0}, 'neutral': {'precision': 1.0, 'recall': 0.5, 'f1-score': 0.6666666666666666, 'support': 14}, 'agree': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0}, 'micro avg': {'precision': 0.5, 'recall': 0.5, 'f1-score': 0.5, 'support': 14}, 'macro avg': {'precision': 0.3333333333333333, 'recall': 0.16666666666666666, 'f1-score': 0.2222222222222222, 'support': 14}, 'weighted avg': {'precision': 1.0, 'recall': 0.5, 'f1-score': 0.6666666666666666, 'support': 14}}\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tVYVmLoZXWem"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}